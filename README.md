# CS292C Project

### Problem

Software verification is a tedious and time consuming approach when done properly. This challenge was taken by the authors of Serval [1], where they introduced a new way to perform an almost automated push-button verification. Their Serval framework takes in the program input and is able to check and identify satisfiability as well as find bugs within the system as demonstrated by their recent paper.

However, the current LLVM verifier constructed in the Serval paper only checks certain undefined behaviors commonly found in ~~C++~~ C programs, such as buffer overflow or oversized shifting. There are plenty of additional problems in ~~C++/~~ C that programs need to be verified for. If we can find propositional logic for the problems not currently verified, we can improve on the current LLVM verifier and check for more bugs while also verifying further the usefulness and effectiveness of push button automation in real world scenarios. Some of the common bugs we have identified are as follows:

- Integer Overflow – Caused by an arithmetic operation that exceeds the maximum size of the integer type used to store it.
- Illegal Memory Access – Created by accessing a memory recently freed without pointer reallocation (also called a dangling pointer or tombstone condition).

These bugs represent some of the common issues with memory management as well as wrap around issues for maximum values of variable types. This project will concentrate on using the information given in the paper to run Serval on new ~~C++~~ C code to verify the program based on the existing logic of the Serval framework. Additionally, this project will attempt to create new propositional logic for the above stated bugs and incorporate it into the Serval framework for superior program verification.


### Challenges

There are a couple limitations and challenges involved in successfully executing this project. The largest challenge arises from the fact that none of the team members have any background in any type of software verification. This places a large learning curve on the team to be able to understand the underlying architecture as well as the implementation of Serval and how it’s able to process finite programs to determine satisfiability. Another challenge is gaining enough background knowledge about compilers and system since most members from the team come from a data science research background.

Since the framework was recently proposed, there aren’t many discussions or citations where people have utilized the framework or experimented with the usage of the framework in an extensive manner. This means we will need to spend time figuring out the limitations of the implementation of the LLVM verifier and it’s closed set of instructions and retrofit our test programs based on what the implemented set of instructions can handle. This brings up another challenge since we have not worked with propositional logic before, we will also need to learn how to build proper propositional logic in an acceptable format for the framework to be able to evaluate and verify our program.

### Solution

Our solution to the above described problems lies in testing the effectiveness and accuracy of the Serval framework. Initially, we will work with the propositional logic for already identified issues to determine what are the exact limitations of implementations within the ~~C++~~ C code that the framework is able to handle. This will require us to write propositional logic for existing issues as well as new issues suggested by us as a part of the project. In our solution we will introduce two existing identified issues as well as a new bug within the code. We will run this logic along with the instruction set generated by LLVM into the interpreter written within Serval for our ~~C++~~ C code.

The Serval framework will process our ~~C++~~ C instruction set generated by LLVM, along with the propositional logic written by us and try to work through the finite program to identify issues/bugs within the code. We will then verify this with our expectation for the programs. This will include identifying all three issues within the code.

### Evaluation Criteria 

We will start by testing the Serval framework using easy programs and examples that the developers of Serval tested with to figure out how to use the framework. We have already tried to run the sample code and CertiKOS verification as suggested by the authors as a part of their introduction [2] to their framework usage. Once we have a good understanding we will write ~~C++~~ C programs that contain bugs and issues that we want to verify and use the Serval framework that we can use to identify where these problems are and if the framework is able to detect the issues. Some of these issues will include incorrect pointer usage, integer overflow, oversize bit shifts etc.

As a part of the testing, we will also record timings for each of the programs recorded in machine time as well as time taken for formal propositional logic recorded in human time similar to the paper. All the code utilized during the course of this project will be available on the Github Repo [3]. All of the testing will be performed using the docker image provided by the authors.

### References

[1] L. Nelson, J. Bornholt, R. Gu, A. Baumann, E. Torlak, and X. Wang, “Scaling symbolic evaluation for automated verification of systems code with serval,” in Proceedings of the 27th ACM Symposium on Operating Systems Principles, ser. SOSP ’19. New York, NY, USA: ACM, 2019, pp. 225–242. [Online]. Available: http://doi.acm.org/10.1145/3341301.3359641

[2] Unsat, “Serval sosp’19 artifact.” [Online]. Available: https://unsat.cs.washington.edu/projects/serval/ sosp19-artifact.html

[3] C. Garg, A. Mathur, and B. Lim, “Cs292c-project-repo,” 2019. [Online]. Available: https://github.com/ chippermist/cs292c-project


### Team Members

- Chinmay Garg
- Aneesha Mathur
- Brian Lim

